{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2\n",
      "  Downloading https://files.pythonhosted.org/packages/83/8d/bbb2ca983f3939066e8d104fe7a7b0fce1fd3d0f706ddb6d8a86bb33f5da/psycopg2-2.8.5-cp37-cp37m-win_amd64.whl (1.1MB)\n",
      "Installing collected packages: psycopg2\n",
      "Successfully installed psycopg2-2.8.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('your engine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_path = 'C:\\\\Users\\\\rtg90\\\\Desktop\\\\Course Material\\\\Stats 170B\\\\CORD-19-research-challenge\\\\biorxiv_medrxiv\\\\biorxiv_medrxiv\\\\pdf_json'\n",
    "bio_doc_list = []\n",
    "\n",
    "for filename in os.listdir(bio_path):\n",
    "    with open(bio_path + \"\\\\\" + filename) as f:\n",
    "        bio_doc_list.append(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_path = 'C:\\\\Users\\\\rtg90\\\\Desktop\\\\Course Material\\\\Stats 170B\\\\CORD-19-research-challenge\\\\comm_use_subset\\\\comm_use_subset\\\\pdf_json'\n",
    "comm_doc_list = []\n",
    "\n",
    "for filename in os.listdir(comm_path):\n",
    "    with open(comm_path + \"\\\\\" + filename) as f:\n",
    "        comm_doc_list.append(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cus_path = 'C:\\\\Users\\\\rtg90\\\\Desktop\\\\Course Material\\\\Stats 170B\\\\CORD-19-research-challenge\\\\custom_license\\\\custom_license\\\\pdf_json'\n",
    "cus_doc_list = []\n",
    "\n",
    "for filename in os.listdir(cus_path):\n",
    "    with open(cus_path + \"\\\\\" + filename) as f:\n",
    "        cus_doc_list.append(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "noncomm_path = 'C:\\\\Users\\\\rtg90\\\\Desktop\\\\Course Material\\\\Stats 170B\\\\CORD-19-research-challenge\\\\noncomm_use_subset\\\\noncomm_use_subset\\\\pdf_json'\n",
    "noncomm_doc_list = []\n",
    "\n",
    "for filename in os.listdir(noncomm_path):\n",
    "    with open(noncomm_path + \"\\\\\" + filename) as f:\n",
    "        noncomm_doc_list.append(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_list = []\n",
    "#article_dict[\"bio\"] = dict()\n",
    "#article_dict[\"comm\"] = dict()\n",
    "#article_dict[\"cus\"] = dict()\n",
    "#article_dict[\"noncomm\"] = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1053 9315 20657 2350\n"
     ]
    }
   ],
   "source": [
    "print(len(bio_doc_list), len(comm_doc_list), len(cus_doc_list), len(noncomm_doc_list)) #ORIGINAL JSON FILE SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1625 9524 26505 2490\n"
     ]
    }
   ],
   "source": [
    "print(len(bio_doc_list), len(comm_doc_list), len(cus_doc_list), len(noncomm_doc_list)) #NEW JSON FILE SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word count: 194 22 Text word count: 5168 23 24 25 author/funder. All rights reserved. No reuse allowed without permission. Abstract 27 The positive stranded RNA genomes of picornaviruses comprise a single large open reading 28 frame flanked by 5′ and 3′ untranslated regions (UTRs). Foot-and-mouth disease virus (FMDV) 29 has an unusually large 5′ UTR (1.3 kb) containing five structural domains. These include the 30 internal ribosome entry site (IRES), which facilitates initiation of translation, and the cis-acting 31 replication element (cre). Less well characterised structures are a 5′ terminal 360 nucleotide 32 stem-loop, a variable length poly-C-tract of approximately 100-200 nucleotides and a series of 33 two to four tandemly repeated pseudoknots (PKs). We investigated the structures of the PKs 34 by selective 2′ hydroxyl acetylation analysed by primer extension (SHAPE) analysis and 35 determined their contribution to genome replication by mutation and deletion experiments. 36 SHAPE and mutation experiments confirmed the importance of the previously predicted PK 37 structures for their function. Deletion experiments showed that although PKs are not essential 38\n"
     ]
    }
   ],
   "source": [
    "print(bio_doc_list[0]['abstract'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VP3, and VP0 (which is further processed to VP2 and VP4 during virus assembly) (6). The P2 64 and P3 regions encode the non-structural proteins 2B and 2C and 3A, 3B (1-3) (VPg), 3C pro and 4 structural protein-coding region is replaced by reporter genes, allow the study of genome 68 replication without the requirement for high containment (9, 10) ( figure 1A ).\n"
     ]
    }
   ],
   "source": [
    "print(bio_doc_list[0]['body_text'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bio': {}, 'comm': {}, 'cus': {}, 'noncomm': {}}\n"
     ]
    }
   ],
   "source": [
    "print(article_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_type = [(\"bio\", bio_doc_list), (\"comm\", comm_doc_list), (\"cus\", cus_doc_list), (\"noncomm\", noncomm_doc_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def abstract_generator(source_tuple, article_dict):\n",
    "    for article in source_tuple[1]:\n",
    "    \n",
    "        for abs in article['abstract']:\n",
    "            if article['paper_id'] not in article_dict[source_tuple[0]]:\n",
    "                article_dict[source_tuple[0]][article['paper_id']] = defaultdict(str)\n",
    "                article_dict[source_tuple[0]][article['paper_id']]['abstract'] = abs['text']\n",
    "            else:\n",
    "                article_dict[source_tuple[0]][article['paper_id']]['abstract'] = article_dict[source_tuple[0]][article['paper_id']]['abstract'] + \" \"+ abs['text']\n",
    "    \n",
    "    return article_dict\n",
    "    \n",
    "    #print(len(article['abstract']))\n",
    "    \n",
    "for tup in source_type:\n",
    "    article_dict = abstract_generator(tup, article_dict)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "article_dict: {source_type: {paper_id: {abstract : text_concatenated} } } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abstract_generator(source_tuple, article_list):\n",
    "    for article in source_tuple[1]:\n",
    "        temp_dict = dict()\n",
    "        temp_dict['id'] = article['paper_id']\n",
    "        temp_dict['type'] = source_tuple[0]\n",
    "        temp_dict['title'] = article['metadata']['title']\n",
    "        temp_dict['abstract'] = \"\"\n",
    "        temp_dict['bodytext'] = \"\"\n",
    "\n",
    "        for abs in article['abstract']:\n",
    "            temp_dict['abstract'] = temp_dict['abstract'] + \" \" + abs['text']\n",
    "        \n",
    "        for body in article['body_text']:\n",
    "            temp_dict['bodytext'] = temp_dict['bodytext'] + \" \" + body['text']\n",
    "        \n",
    "        article_list.append(temp_dict)\n",
    "\n",
    "    return article_list\n",
    "    \n",
    "    #print(len(article['abstract']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tup in source_type:\n",
    "    article_list = abstract_generator(tup, article_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40144\n"
     ]
    }
   ],
   "source": [
    "print(len(article_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24827\n"
     ]
    }
   ],
   "source": [
    "print(len(article_dict['bio']) + len(article_dict['comm']) + len(article_dict['noncomm']) + len(article_dict['cus'])) #ORIGINAL FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40144\n"
     ]
    }
   ],
   "source": [
    "print(len(bio_doc_list) + len(comm_doc_list) + len(cus_doc_list) + len(noncomm_doc_list)) #NEW FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>bodytext</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>word count: 194 22 Text word count: 5168 23 2...</td>\n",
       "      <td>VP3, and VP0 (which is further processed to V...</td>\n",
       "      <td>0015023cc06b5362d332b3baf348d11567ca2fbb</td>\n",
       "      <td>The RNA pseudoknots in foot-and-mouth disease ...</td>\n",
       "      <td>bio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>During the past three months, a new coronavir...</td>\n",
       "      <td>In December 2019, a novel coronavirus, SARS-C...</td>\n",
       "      <td>00340eea543336d54adda18236424de6a5e91c9d</td>\n",
       "      <td>Analysis Title: Regaining perspective on SARS-...</td>\n",
       "      <td>bio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>The 2019-nCoV epidemic has spread across Chin...</td>\n",
       "      <td>004f0f8bb66cf446678dc13cf2701feec4f36d76</td>\n",
       "      <td>Healthcare-resource-adjusted vulnerabilities t...</td>\n",
       "      <td>bio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The fast accumulation of viral metagenomic da...</td>\n",
       "      <td>Metagenomic sequencing, which allows us to di...</td>\n",
       "      <td>00911cf4f99a3d5ae5e5b787675646a743574496</td>\n",
       "      <td>CHEER: hierarCHical taxonomic classification f...</td>\n",
       "      <td>bio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Infectious bronchitis (IB) causes significant...</td>\n",
       "      <td>Infectious bronchitis (IB), which is caused b...</td>\n",
       "      <td>00d16927588fb04d4be0e6b269fc02f0d3c2aa7b</td>\n",
       "      <td>Real-time, MinION-based, amplicon sequencing f...</td>\n",
       "      <td>bio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract  \\\n",
       "0   word count: 194 22 Text word count: 5168 23 2...   \n",
       "1   During the past three months, a new coronavir...   \n",
       "2                                                      \n",
       "3   The fast accumulation of viral metagenomic da...   \n",
       "4   Infectious bronchitis (IB) causes significant...   \n",
       "\n",
       "                                            bodytext  \\\n",
       "0   VP3, and VP0 (which is further processed to V...   \n",
       "1   In December 2019, a novel coronavirus, SARS-C...   \n",
       "2   The 2019-nCoV epidemic has spread across Chin...   \n",
       "3   Metagenomic sequencing, which allows us to di...   \n",
       "4   Infectious bronchitis (IB), which is caused b...   \n",
       "\n",
       "                                         id  \\\n",
       "0  0015023cc06b5362d332b3baf348d11567ca2fbb   \n",
       "1  00340eea543336d54adda18236424de6a5e91c9d   \n",
       "2  004f0f8bb66cf446678dc13cf2701feec4f36d76   \n",
       "3  00911cf4f99a3d5ae5e5b787675646a743574496   \n",
       "4  00d16927588fb04d4be0e6b269fc02f0d3c2aa7b   \n",
       "\n",
       "                                               title type  \n",
       "0  The RNA pseudoknots in foot-and-mouth disease ...  bio  \n",
       "1  Analysis Title: Regaining perspective on SARS-...  bio  \n",
       "2  Healthcare-resource-adjusted vulnerabilities t...  bio  \n",
       "3  CHEER: hierarCHical taxonomic classification f...  bio  \n",
       "4  Real-time, MinION-based, amplicon sequencing f...  bio  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df = pd.DataFrame(article_list)\n",
    "article_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df.to_sql('articles', con=engine, index = False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>bodytext</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>word count: 194 22 Text word count: 5168 23 2...</td>\n",
       "      <td>VP3, and VP0 (which is further processed to V...</td>\n",
       "      <td>0015023cc06b5362d332b3baf348d11567ca2fbb</td>\n",
       "      <td>The RNA pseudoknots in foot-and-mouth disease ...</td>\n",
       "      <td>bio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>During the past three months, a new coronavir...</td>\n",
       "      <td>In December 2019, a novel coronavirus, SARS-C...</td>\n",
       "      <td>00340eea543336d54adda18236424de6a5e91c9d</td>\n",
       "      <td>Analysis Title: Regaining perspective on SARS-...</td>\n",
       "      <td>bio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>The 2019-nCoV epidemic has spread across Chin...</td>\n",
       "      <td>004f0f8bb66cf446678dc13cf2701feec4f36d76</td>\n",
       "      <td>Healthcare-resource-adjusted vulnerabilities t...</td>\n",
       "      <td>bio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The fast accumulation of viral metagenomic da...</td>\n",
       "      <td>Metagenomic sequencing, which allows us to di...</td>\n",
       "      <td>00911cf4f99a3d5ae5e5b787675646a743574496</td>\n",
       "      <td>CHEER: hierarCHical taxonomic classification f...</td>\n",
       "      <td>bio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Infectious bronchitis (IB) causes significant...</td>\n",
       "      <td>Infectious bronchitis (IB), which is caused b...</td>\n",
       "      <td>00d16927588fb04d4be0e6b269fc02f0d3c2aa7b</td>\n",
       "      <td>Real-time, MinION-based, amplicon sequencing f...</td>\n",
       "      <td>bio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract  \\\n",
       "0   word count: 194 22 Text word count: 5168 23 2...   \n",
       "1   During the past three months, a new coronavir...   \n",
       "2                                                      \n",
       "3   The fast accumulation of viral metagenomic da...   \n",
       "4   Infectious bronchitis (IB) causes significant...   \n",
       "\n",
       "                                            bodytext  \\\n",
       "0   VP3, and VP0 (which is further processed to V...   \n",
       "1   In December 2019, a novel coronavirus, SARS-C...   \n",
       "2   The 2019-nCoV epidemic has spread across Chin...   \n",
       "3   Metagenomic sequencing, which allows us to di...   \n",
       "4   Infectious bronchitis (IB), which is caused b...   \n",
       "\n",
       "                                         id  \\\n",
       "0  0015023cc06b5362d332b3baf348d11567ca2fbb   \n",
       "1  00340eea543336d54adda18236424de6a5e91c9d   \n",
       "2  004f0f8bb66cf446678dc13cf2701feec4f36d76   \n",
       "3  00911cf4f99a3d5ae5e5b787675646a743574496   \n",
       "4  00d16927588fb04d4be0e6b269fc02f0d3c2aa7b   \n",
       "\n",
       "                                               title type  \n",
       "0  The RNA pseudoknots in foot-and-mouth disease ...  bio  \n",
       "1  Analysis Title: Regaining perspective on SARS-...  bio  \n",
       "2  Healthcare-resource-adjusted vulnerabilities t...  bio  \n",
       "3  CHEER: hierarCHical taxonomic classification f...  bio  \n",
       "4  Real-time, MinION-based, amplicon sequencing f...  bio  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df = pd.read_sql_query('SELECT * from articles',con=engine)\n",
    "article_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40144\n",
      "40144\n"
     ]
    }
   ],
   "source": [
    "print(len(article_df))\n",
    "temp_set = set()\n",
    "for id in article_df['id']:\n",
    "    temp_set.add(id)\n",
    "    \n",
    "print(len(temp_set))\n",
    "#ALL ARTICLES ARE UNIQUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_abs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(article_df)):\n",
    "    temp_str = article_df.iloc[i]['title'] + \"\\n\" + article_df.iloc[i]['abstract']\n",
    "    title_abs.append(temp_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_abs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(article_df)):\n",
    "    temp_str = article_df.iloc[i]['abstract']\n",
    "    only_abs.append(temp_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SnowballStemmer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f6103652ca0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstemmer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSnowballStemmer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"english\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mstopwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtokenize_and_stem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SnowballStemmer' is not defined"
     ]
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def tokenize_and_stem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token) and len(token) > 1 and token not in stopwords:\n",
    "            filtered_tokens.append(token)\n",
    "    #print(filtered_tokens)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    #print(stems)\n",
    "    return stems\n",
    "\n",
    "tokenize_and_stem(\"Obviously, 'd aa z this d. ' ` ,'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.80, min_df = 0.05, max_features = 10000, tokenizer = tokenize_and_stem, ngram_range = (1,3))\n",
    "vectors = vectorizer.fit_transform(title_abs)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>'s</th>\n",
       "      <th>acid</th>\n",
       "      <th>activ</th>\n",
       "      <th>acut</th>\n",
       "      <th>acut respiratori</th>\n",
       "      <th>acut respiratori syndrom</th>\n",
       "      <th>addit</th>\n",
       "      <th>affect</th>\n",
       "      <th>age</th>\n",
       "      <th>agent</th>\n",
       "      <th>...</th>\n",
       "      <th>vaccin</th>\n",
       "      <th>various</th>\n",
       "      <th>viral</th>\n",
       "      <th>viral infect</th>\n",
       "      <th>virus</th>\n",
       "      <th>vitro</th>\n",
       "      <th>well</th>\n",
       "      <th>within</th>\n",
       "      <th>without</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.193800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187345</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.286303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.02239</td>\n",
       "      <td>0.021834</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.077873</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064031</td>\n",
       "      <td>0.117887</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 266 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        's      acid  activ  acut  acut respiratori  acut respiratori syndrom  \\\n",
       "0  0.00000  0.000000    0.0   0.0               0.0                       0.0   \n",
       "1  0.00000  0.000000    0.0   0.0               0.0                       0.0   \n",
       "2  0.00000  0.000000    0.0   0.0               0.0                       0.0   \n",
       "3  0.00000  0.000000    0.0   0.0               0.0                       0.0   \n",
       "4  0.02239  0.021834    0.0   0.0               0.0                       0.0   \n",
       "\n",
       "      addit    affect  age     agent  ...    vaccin  various     viral  \\\n",
       "0  0.000000  0.000000  0.0  0.000000  ...  0.000000      0.0  0.000000   \n",
       "1  0.000000  0.286303  0.0  0.000000  ...  0.000000      0.0  0.094457   \n",
       "2  0.000000  0.000000  0.0  0.000000  ...  0.000000      0.0  0.000000   \n",
       "3  0.000000  0.000000  0.0  0.000000  ...  0.000000      0.0  0.272689   \n",
       "4  0.077873  0.000000  0.0  0.022322  ...  0.079532      0.0  0.030010   \n",
       "\n",
       "   viral infect     virus  vitro      well    within   without  year  \n",
       "0           0.0  0.193800    0.0  0.078140  0.000000  0.187345   0.0  \n",
       "1           0.0  0.000000    0.0  0.123811  0.000000  0.000000   0.0  \n",
       "2           0.0  0.000000    0.0  0.000000  0.000000  0.000000   0.0  \n",
       "3           0.0  0.073874    0.0  0.000000  0.000000  0.000000   0.0  \n",
       "4           0.0  0.097560    0.0  0.000000  0.064031  0.117887   0.0  \n",
       "\n",
       "[5 rows x 266 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt =0\n",
    "for x in df.columns:\n",
    "    try:\n",
    "        int(x)\n",
    "        cnt += 1\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40144 entries, 0 to 40143\n",
      "Data columns (total 5 columns):\n",
      "abstract    40144 non-null object\n",
      "bodytext    40144 non-null object\n",
      "id          40144 non-null object\n",
      "title       40144 non-null object\n",
      "type        40144 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "article_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
