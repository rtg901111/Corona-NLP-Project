{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "from pyLDAvis import sklearn as sklearn_lda\n",
    "import pickle \n",
    "import pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql+psycopg2://postgres:@localhost/stats170b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_path = 'C:\\\\Users\\\\rtg90\\\\Desktop\\\\Course Material\\\\Stats 170B\\\\CORD-19-research-challenge\\\\biorxiv_medrxiv\\\\biorxiv_medrxiv\\\\pdf_json'\n",
    "bio_doc_list = []\n",
    "\n",
    "for filename in os.listdir(bio_path):\n",
    "    with open(bio_path + \"\\\\\" + filename) as f:\n",
    "        bio_doc_list.append(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_path = 'C:\\\\Users\\\\rtg90\\\\Desktop\\\\Course Material\\\\Stats 170B\\\\CORD-19-research-challenge\\\\comm_use_subset\\\\comm_use_subset\\\\pdf_json'\n",
    "comm_doc_list = []\n",
    "\n",
    "for filename in os.listdir(comm_path):\n",
    "    with open(comm_path + \"\\\\\" + filename) as f:\n",
    "        comm_doc_list.append(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cus_path = 'C:\\\\Users\\\\rtg90\\\\Desktop\\\\Course Material\\\\Stats 170B\\\\CORD-19-research-challenge\\\\custom_license\\\\custom_license\\\\pdf_json'\n",
    "cus_doc_list = []\n",
    "\n",
    "for filename in os.listdir(cus_path):\n",
    "    with open(cus_path + \"\\\\\" + filename) as f:\n",
    "        cus_doc_list.append(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "noncomm_path = 'C:\\\\Users\\\\rtg90\\\\Desktop\\\\Course Material\\\\Stats 170B\\\\CORD-19-research-challenge\\\\noncomm_use_subset\\\\noncomm_use_subset\\\\pdf_json'\n",
    "noncomm_doc_list = []\n",
    "\n",
    "for filename in os.listdir(noncomm_path):\n",
    "    with open(noncomm_path + \"\\\\\" + filename) as f:\n",
    "        noncomm_doc_list.append(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_list = []\n",
    "#article_dict[\"bio\"] = dict()\n",
    "#article_dict[\"comm\"] = dict()\n",
    "#article_dict[\"cus\"] = dict()\n",
    "#article_dict[\"noncomm\"] = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1053 9315 20657 2350\n"
     ]
    }
   ],
   "source": [
    "print(len(bio_doc_list), len(comm_doc_list), len(cus_doc_list), len(noncomm_doc_list)) #ORIGINAL JSON FILE SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1625 9524 26505 2490\n"
     ]
    }
   ],
   "source": [
    "print(len(bio_doc_list), len(comm_doc_list), len(cus_doc_list), len(noncomm_doc_list)) #NEW JSON FILE SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word count: 194 22 Text word count: 5168 23 24 25 author/funder. All rights reserved. No reuse allowed without permission. Abstract 27 The positive stranded RNA genomes of picornaviruses comprise a single large open reading 28 frame flanked by 5′ and 3′ untranslated regions (UTRs). Foot-and-mouth disease virus (FMDV) 29 has an unusually large 5′ UTR (1.3 kb) containing five structural domains. These include the 30 internal ribosome entry site (IRES), which facilitates initiation of translation, and the cis-acting 31 replication element (cre). Less well characterised structures are a 5′ terminal 360 nucleotide 32 stem-loop, a variable length poly-C-tract of approximately 100-200 nucleotides and a series of 33 two to four tandemly repeated pseudoknots (PKs). We investigated the structures of the PKs 34 by selective 2′ hydroxyl acetylation analysed by primer extension (SHAPE) analysis and 35 determined their contribution to genome replication by mutation and deletion experiments. 36 SHAPE and mutation experiments confirmed the importance of the previously predicted PK 37 structures for their function. Deletion experiments showed that although PKs are not essential 38\n"
     ]
    }
   ],
   "source": [
    "print(bio_doc_list[0]['abstract'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VP3, and VP0 (which is further processed to VP2 and VP4 during virus assembly) (6). The P2 64 and P3 regions encode the non-structural proteins 2B and 2C and 3A, 3B (1-3) (VPg), 3C pro and 4 structural protein-coding region is replaced by reporter genes, allow the study of genome 68 replication without the requirement for high containment (9, 10) ( figure 1A ).\n"
     ]
    }
   ],
   "source": [
    "print(bio_doc_list[0]['body_text'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bio': {}, 'comm': {}, 'cus': {}, 'noncomm': {}}\n"
     ]
    }
   ],
   "source": [
    "print(article_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_type = [(\"bio\", bio_doc_list), (\"comm\", comm_doc_list), (\"cus\", cus_doc_list), (\"noncomm\", noncomm_doc_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def abstract_generator(source_tuple, article_dict):\n",
    "    for article in source_tuple[1]:\n",
    "    \n",
    "        for abs in article['abstract']:\n",
    "            if article['paper_id'] not in article_dict[source_tuple[0]]:\n",
    "                article_dict[source_tuple[0]][article['paper_id']] = defaultdict(str)\n",
    "                article_dict[source_tuple[0]][article['paper_id']]['abstract'] = abs['text']\n",
    "            else:\n",
    "                article_dict[source_tuple[0]][article['paper_id']]['abstract'] = article_dict[source_tuple[0]][article['paper_id']]['abstract'] + \" \"+ abs['text']\n",
    "    \n",
    "    return article_dict\n",
    "    \n",
    "    #print(len(article['abstract']))\n",
    "    \n",
    "for tup in source_type:\n",
    "    article_dict = abstract_generator(tup, article_dict)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "article_dict: {source_type: {paper_id: {abstract : text_concatenated} } } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abstract_generator(source_tuple, article_list):\n",
    "    for article in source_tuple[1]:\n",
    "        temp_dict = dict()\n",
    "        temp_dict['id'] = article['paper_id']\n",
    "        temp_dict['type'] = source_tuple[0]\n",
    "        temp_dict['title'] = article['metadata']['title']\n",
    "        temp_dict['abstract'] = \"\"\n",
    "        temp_dict['bodytext'] = \"\"\n",
    "\n",
    "        for abs in article['abstract']:\n",
    "            temp_dict['abstract'] = temp_dict['abstract'] + \" \" + abs['text']\n",
    "        \n",
    "        for body in article['body_text']:\n",
    "            temp_dict['bodytext'] = temp_dict['bodytext'] + \" \" + body['text']\n",
    "        \n",
    "        article_list.append(temp_dict)\n",
    "\n",
    "    return article_list\n",
    "    \n",
    "    #print(len(article['abstract']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tup in source_type:\n",
    "    article_list = abstract_generator(tup, article_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40144\n"
     ]
    }
   ],
   "source": [
    "print(len(article_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24827\n"
     ]
    }
   ],
   "source": [
    "print(len(article_dict['bio']) + len(article_dict['comm']) + len(article_dict['noncomm']) + len(article_dict['cus'])) #ORIGINAL FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40144\n"
     ]
    }
   ],
   "source": [
    "print(len(bio_doc_list) + len(comm_doc_list) + len(cus_doc_list) + len(noncomm_doc_list)) #NEW FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>bodytext</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>word count: 194 22 Text word count: 5168 23 2...</td>\n",
       "      <td>VP3, and VP0 (which is further processed to V...</td>\n",
       "      <td>0015023cc06b5362d332b3baf348d11567ca2fbb</td>\n",
       "      <td>The RNA pseudoknots in foot-and-mouth disease ...</td>\n",
       "      <td>bio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>During the past three months, a new coronavir...</td>\n",
       "      <td>In December 2019, a novel coronavirus, SARS-C...</td>\n",
       "      <td>00340eea543336d54adda18236424de6a5e91c9d</td>\n",
       "      <td>Analysis Title: Regaining perspective on SARS-...</td>\n",
       "      <td>bio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>The 2019-nCoV epidemic has spread across Chin...</td>\n",
       "      <td>004f0f8bb66cf446678dc13cf2701feec4f36d76</td>\n",
       "      <td>Healthcare-resource-adjusted vulnerabilities t...</td>\n",
       "      <td>bio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The fast accumulation of viral metagenomic da...</td>\n",
       "      <td>Metagenomic sequencing, which allows us to di...</td>\n",
       "      <td>00911cf4f99a3d5ae5e5b787675646a743574496</td>\n",
       "      <td>CHEER: hierarCHical taxonomic classification f...</td>\n",
       "      <td>bio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Infectious bronchitis (IB) causes significant...</td>\n",
       "      <td>Infectious bronchitis (IB), which is caused b...</td>\n",
       "      <td>00d16927588fb04d4be0e6b269fc02f0d3c2aa7b</td>\n",
       "      <td>Real-time, MinION-based, amplicon sequencing f...</td>\n",
       "      <td>bio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract  \\\n",
       "0   word count: 194 22 Text word count: 5168 23 2...   \n",
       "1   During the past three months, a new coronavir...   \n",
       "2                                                      \n",
       "3   The fast accumulation of viral metagenomic da...   \n",
       "4   Infectious bronchitis (IB) causes significant...   \n",
       "\n",
       "                                            bodytext  \\\n",
       "0   VP3, and VP0 (which is further processed to V...   \n",
       "1   In December 2019, a novel coronavirus, SARS-C...   \n",
       "2   The 2019-nCoV epidemic has spread across Chin...   \n",
       "3   Metagenomic sequencing, which allows us to di...   \n",
       "4   Infectious bronchitis (IB), which is caused b...   \n",
       "\n",
       "                                         id  \\\n",
       "0  0015023cc06b5362d332b3baf348d11567ca2fbb   \n",
       "1  00340eea543336d54adda18236424de6a5e91c9d   \n",
       "2  004f0f8bb66cf446678dc13cf2701feec4f36d76   \n",
       "3  00911cf4f99a3d5ae5e5b787675646a743574496   \n",
       "4  00d16927588fb04d4be0e6b269fc02f0d3c2aa7b   \n",
       "\n",
       "                                               title type  \n",
       "0  The RNA pseudoknots in foot-and-mouth disease ...  bio  \n",
       "1  Analysis Title: Regaining perspective on SARS-...  bio  \n",
       "2  Healthcare-resource-adjusted vulnerabilities t...  bio  \n",
       "3  CHEER: hierarCHical taxonomic classification f...  bio  \n",
       "4  Real-time, MinION-based, amplicon sequencing f...  bio  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df = pd.DataFrame(article_list)\n",
    "article_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df.to_sql('articles', con=engine, index = False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN FROM HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>bodytext</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>topic</th>\n",
       "      <th>topic_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>word count: 194 22 Text word count: 5168 23 2...</td>\n",
       "      <td>VP3, and VP0 (which is further processed to V...</td>\n",
       "      <td>0015023cc06b5362d332b3baf348d11567ca2fbb</td>\n",
       "      <td>The RNA pseudoknots in foot-and-mouth disease ...</td>\n",
       "      <td>bio</td>\n",
       "      <td>1</td>\n",
       "      <td>rna sequence gene sequences pcr using genome d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>During the past three months, a new coronavir...</td>\n",
       "      <td>In December 2019, a novel coronavirus, SARS-C...</td>\n",
       "      <td>00340eea543336d54adda18236424de6a5e91c9d</td>\n",
       "      <td>Analysis Title: Regaining perspective on SARS-...</td>\n",
       "      <td>bio</td>\n",
       "      <td>2</td>\n",
       "      <td>data model number time used using 10 rate case...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>The 2019-nCoV epidemic has spread across Chin...</td>\n",
       "      <td>004f0f8bb66cf446678dc13cf2701feec4f36d76</td>\n",
       "      <td>Healthcare-resource-adjusted vulnerabilities t...</td>\n",
       "      <td>bio</td>\n",
       "      <td>2</td>\n",
       "      <td>data model number time used using 10 rate case...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The fast accumulation of viral metagenomic da...</td>\n",
       "      <td>Metagenomic sequencing, which allows us to di...</td>\n",
       "      <td>00911cf4f99a3d5ae5e5b787675646a743574496</td>\n",
       "      <td>CHEER: hierarCHical taxonomic classification f...</td>\n",
       "      <td>bio</td>\n",
       "      <td>2</td>\n",
       "      <td>data model number time used using 10 rate case...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Infectious bronchitis (IB) causes significant...</td>\n",
       "      <td>Infectious bronchitis (IB), which is caused b...</td>\n",
       "      <td>00d16927588fb04d4be0e6b269fc02f0d3c2aa7b</td>\n",
       "      <td>Real-time, MinION-based, amplicon sequencing f...</td>\n",
       "      <td>bio</td>\n",
       "      <td>1</td>\n",
       "      <td>rna sequence gene sequences pcr using genome d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract  \\\n",
       "0   word count: 194 22 Text word count: 5168 23 2...   \n",
       "1   During the past three months, a new coronavir...   \n",
       "2                                                      \n",
       "3   The fast accumulation of viral metagenomic da...   \n",
       "4   Infectious bronchitis (IB) causes significant...   \n",
       "\n",
       "                                            bodytext  \\\n",
       "0   VP3, and VP0 (which is further processed to V...   \n",
       "1   In December 2019, a novel coronavirus, SARS-C...   \n",
       "2   The 2019-nCoV epidemic has spread across Chin...   \n",
       "3   Metagenomic sequencing, which allows us to di...   \n",
       "4   Infectious bronchitis (IB), which is caused b...   \n",
       "\n",
       "                                         id  \\\n",
       "0  0015023cc06b5362d332b3baf348d11567ca2fbb   \n",
       "1  00340eea543336d54adda18236424de6a5e91c9d   \n",
       "2  004f0f8bb66cf446678dc13cf2701feec4f36d76   \n",
       "3  00911cf4f99a3d5ae5e5b787675646a743574496   \n",
       "4  00d16927588fb04d4be0e6b269fc02f0d3c2aa7b   \n",
       "\n",
       "                                               title type  topic  \\\n",
       "0  The RNA pseudoknots in foot-and-mouth disease ...  bio      1   \n",
       "1  Analysis Title: Regaining perspective on SARS-...  bio      2   \n",
       "2  Healthcare-resource-adjusted vulnerabilities t...  bio      2   \n",
       "3  CHEER: hierarCHical taxonomic classification f...  bio      2   \n",
       "4  Real-time, MinION-based, amplicon sequencing f...  bio      1   \n",
       "\n",
       "                                           topic_str  \n",
       "0  rna sequence gene sequences pcr using genome d...  \n",
       "1  data model number time used using 10 rate case...  \n",
       "2  data model number time used using 10 rate case...  \n",
       "3  data model number time used using 10 rate case...  \n",
       "4  rna sequence gene sequences pcr using genome d...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df = pd.read_sql_query('SELECT * from articles',con=engine)\n",
    "article_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40144\n",
      "40144\n"
     ]
    }
   ],
   "source": [
    "print(len(article_df))\n",
    "temp_set = set()\n",
    "for id in article_df['id']:\n",
    "    temp_set.add(id)\n",
    "    \n",
    "print(len(temp_set))\n",
    "#ALL ARTICLES ARE UNIQUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_abs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(article_df)):\n",
    "    temp_str = article_df.iloc[i]['title'] + \"\\n\" + article_df.iloc[i]['abstract']\n",
    "    title_abs.append(temp_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_abs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(article_df)):\n",
    "    temp_str = article_df.iloc[i]['abstract']\n",
    "    only_abs.append(temp_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['obvious', \"'d\", 'aa', 'd.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def tokenize_and_stem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token) and len(token) > 1 and token not in stopwords:\n",
    "            filtered_tokens.append(token)\n",
    "    #print(filtered_tokens)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    #print(stems)\n",
    "    return stems\n",
    "\n",
    "tokenize_and_stem(\"Obviously, 'd aa z this d. ' ` ,'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.80, min_df = 0.05, max_features = 10000, tokenizer = tokenize_and_stem, ngram_range = (1,3))\n",
    "vectors = vectorizer.fit_transform(title_abs)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>'s</th>\n",
       "      <th>acid</th>\n",
       "      <th>activ</th>\n",
       "      <th>acut</th>\n",
       "      <th>acut respiratori</th>\n",
       "      <th>acut respiratori syndrom</th>\n",
       "      <th>addit</th>\n",
       "      <th>affect</th>\n",
       "      <th>age</th>\n",
       "      <th>agent</th>\n",
       "      <th>...</th>\n",
       "      <th>vaccin</th>\n",
       "      <th>various</th>\n",
       "      <th>viral</th>\n",
       "      <th>viral infect</th>\n",
       "      <th>virus</th>\n",
       "      <th>vitro</th>\n",
       "      <th>well</th>\n",
       "      <th>within</th>\n",
       "      <th>without</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.193800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187345</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.286303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.02239</td>\n",
       "      <td>0.021834</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.077873</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064031</td>\n",
       "      <td>0.117887</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 266 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        's      acid  activ  acut  acut respiratori  acut respiratori syndrom  \\\n",
       "0  0.00000  0.000000    0.0   0.0               0.0                       0.0   \n",
       "1  0.00000  0.000000    0.0   0.0               0.0                       0.0   \n",
       "2  0.00000  0.000000    0.0   0.0               0.0                       0.0   \n",
       "3  0.00000  0.000000    0.0   0.0               0.0                       0.0   \n",
       "4  0.02239  0.021834    0.0   0.0               0.0                       0.0   \n",
       "\n",
       "      addit    affect  age     agent  ...    vaccin  various     viral  \\\n",
       "0  0.000000  0.000000  0.0  0.000000  ...  0.000000      0.0  0.000000   \n",
       "1  0.000000  0.286303  0.0  0.000000  ...  0.000000      0.0  0.094457   \n",
       "2  0.000000  0.000000  0.0  0.000000  ...  0.000000      0.0  0.000000   \n",
       "3  0.000000  0.000000  0.0  0.000000  ...  0.000000      0.0  0.272689   \n",
       "4  0.077873  0.000000  0.0  0.022322  ...  0.079532      0.0  0.030010   \n",
       "\n",
       "   viral infect     virus  vitro      well    within   without  year  \n",
       "0           0.0  0.193800    0.0  0.078140  0.000000  0.187345   0.0  \n",
       "1           0.0  0.000000    0.0  0.123811  0.000000  0.000000   0.0  \n",
       "2           0.0  0.000000    0.0  0.000000  0.000000  0.000000   0.0  \n",
       "3           0.0  0.073874    0.0  0.000000  0.000000  0.000000   0.0  \n",
       "4           0.0  0.097560    0.0  0.000000  0.064031  0.117887   0.0  \n",
       "\n",
       "[5 rows x 266 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f979030ed5cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcnt\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mcnt\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "cnt =0\n",
    "for x in df.columns:\n",
    "    try:\n",
    "        int(x)\n",
    "        cnt += 1\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_topics = 10\n",
    "number_words = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "count_data = count_vectorizer.fit_transform(article_df['bodytext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lda = LDA(n_components=number_topics, learning_method='online', n_jobs=-1)\n",
    "#lda.fit(count_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics found via LDA:\n",
      "\n",
      "Topic #0:\n",
      "health public care risk disease research information countries use diseases\n",
      "\n",
      "Topic #1:\n",
      "rna sequence gene sequences pcr using genome dna genes protein\n",
      "\n",
      "Topic #2:\n",
      "data model number time used using 10 rate cases different\n",
      "\n",
      "Topic #3:\n",
      "cells cell mice immune expression il response ifn infection induced\n",
      "\n",
      "Topic #4:\n",
      "la en des les el et le que los se\n",
      "\n",
      "Topic #5:\n",
      "cells 10 virus cell fig using protein ml infected infection\n",
      "\n",
      "Topic #6:\n",
      "patients study respiratory infection clinical children patient treatment cases infections\n",
      "\n",
      "Topic #7:\n",
      "virus al et viruses infection human influenza viral vaccine disease\n",
      "\n",
      "Topic #8:\n",
      "disease animals cats dogs blood signs lesions calves clinical diarrhea\n",
      "\n",
      "Topic #9:\n",
      "et al protein proteins binding activity membrane cell structure acid\n"
     ]
    }
   ],
   "source": [
    "def print_topics(model, count_vectorizer, n_top_words):\n",
    "    top_topics = []\n",
    "    words = count_vectorizer.get_feature_names()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic #%d:\" % topic_idx)\n",
    "        topic = \" \".join([words[i] for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        top_topics.append(topic)\n",
    "        print(topic)\n",
    "        \n",
    "    return top_topics\n",
    "\n",
    "print(\"Topics found via LDA:\")\n",
    "top_topics = print_topics(lda, count_vectorizer, number_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(lda, open('initial_lda_model.pk', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = pickle.load(open('initial_lda_model.pk', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic = lda.transform(count_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_list = []\n",
    "topic_str_list = []\n",
    "\n",
    "for i in range(doc_topic.shape[0]):\n",
    "    topic_most_pr = doc_topic[i].argmax()\n",
    "    topic_list.append(topic_most_pr)    \n",
    "    \n",
    "    topic_str = top_topics[topic_most_pr]\n",
    "    topic_str_list.append(topic_str)\n",
    "\n",
    "article_df['topic'] = topic_list\n",
    "article_df['topic_str'] = topic_str_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>bodytext</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>topic</th>\n",
       "      <th>topic_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>word count: 194 22 Text word count: 5168 23 2...</td>\n",
       "      <td>VP3, and VP0 (which is further processed to V...</td>\n",
       "      <td>0015023cc06b5362d332b3baf348d11567ca2fbb</td>\n",
       "      <td>The RNA pseudoknots in foot-and-mouth disease ...</td>\n",
       "      <td>bio</td>\n",
       "      <td>1</td>\n",
       "      <td>rna sequence gene sequences pcr using genome d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>During the past three months, a new coronavir...</td>\n",
       "      <td>In December 2019, a novel coronavirus, SARS-C...</td>\n",
       "      <td>00340eea543336d54adda18236424de6a5e91c9d</td>\n",
       "      <td>Analysis Title: Regaining perspective on SARS-...</td>\n",
       "      <td>bio</td>\n",
       "      <td>2</td>\n",
       "      <td>data model number time used using 10 rate case...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>The 2019-nCoV epidemic has spread across Chin...</td>\n",
       "      <td>004f0f8bb66cf446678dc13cf2701feec4f36d76</td>\n",
       "      <td>Healthcare-resource-adjusted vulnerabilities t...</td>\n",
       "      <td>bio</td>\n",
       "      <td>2</td>\n",
       "      <td>data model number time used using 10 rate case...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The fast accumulation of viral metagenomic da...</td>\n",
       "      <td>Metagenomic sequencing, which allows us to di...</td>\n",
       "      <td>00911cf4f99a3d5ae5e5b787675646a743574496</td>\n",
       "      <td>CHEER: hierarCHical taxonomic classification f...</td>\n",
       "      <td>bio</td>\n",
       "      <td>2</td>\n",
       "      <td>data model number time used using 10 rate case...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Infectious bronchitis (IB) causes significant...</td>\n",
       "      <td>Infectious bronchitis (IB), which is caused b...</td>\n",
       "      <td>00d16927588fb04d4be0e6b269fc02f0d3c2aa7b</td>\n",
       "      <td>Real-time, MinION-based, amplicon sequencing f...</td>\n",
       "      <td>bio</td>\n",
       "      <td>1</td>\n",
       "      <td>rna sequence gene sequences pcr using genome d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract  \\\n",
       "0   word count: 194 22 Text word count: 5168 23 2...   \n",
       "1   During the past three months, a new coronavir...   \n",
       "2                                                      \n",
       "3   The fast accumulation of viral metagenomic da...   \n",
       "4   Infectious bronchitis (IB) causes significant...   \n",
       "\n",
       "                                            bodytext  \\\n",
       "0   VP3, and VP0 (which is further processed to V...   \n",
       "1   In December 2019, a novel coronavirus, SARS-C...   \n",
       "2   The 2019-nCoV epidemic has spread across Chin...   \n",
       "3   Metagenomic sequencing, which allows us to di...   \n",
       "4   Infectious bronchitis (IB), which is caused b...   \n",
       "\n",
       "                                         id  \\\n",
       "0  0015023cc06b5362d332b3baf348d11567ca2fbb   \n",
       "1  00340eea543336d54adda18236424de6a5e91c9d   \n",
       "2  004f0f8bb66cf446678dc13cf2701feec4f36d76   \n",
       "3  00911cf4f99a3d5ae5e5b787675646a743574496   \n",
       "4  00d16927588fb04d4be0e6b269fc02f0d3c2aa7b   \n",
       "\n",
       "                                               title type  topic  \\\n",
       "0  The RNA pseudoknots in foot-and-mouth disease ...  bio      1   \n",
       "1  Analysis Title: Regaining perspective on SARS-...  bio      2   \n",
       "2  Healthcare-resource-adjusted vulnerabilities t...  bio      2   \n",
       "3  CHEER: hierarCHical taxonomic classification f...  bio      2   \n",
       "4  Real-time, MinION-based, amplicon sequencing f...  bio      1   \n",
       "\n",
       "                                           topic_str  \n",
       "0  rna sequence gene sequences pcr using genome d...  \n",
       "1  data model number time used using 10 rate case...  \n",
       "2  data model number time used using 10 rate case...  \n",
       "3  data model number time used using 10 rate case...  \n",
       "4  rna sequence gene sequences pcr using genome d...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6616"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(article_df[article_df['topic'] == 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5398"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(article_df[article_df['topic'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40144, 7)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDAvis_data_filepath = os.path.join('./ldavis_prepared_initial_'+ str(number_topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDAvis_prepared = sklearn_lda.prepare(lda, count_data, count_vectorizer)\n",
    "#with open(LDAvis_data_filepath, 'w') as f:\n",
    "#        pickle.dump(LDAvis_prepared, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(LDAvis_prepared, open(LDAvis_data_filepath, 'wb'))\n",
    "        \n",
    "        \n",
    "\n",
    "# load the pre-prepared pyLDAvis data from disk\n",
    "#with open(LDAvis_data_filepath) as f:\n",
    "#    LDAvis_prepared = pickle.load(f)\n",
    "LDAvis_prepared = pickle.load(open(LDAvis_data_filepath, 'rb'))\n",
    "\n",
    "    \n",
    "#pyLDAvis.save_html(LDAvis_prepared, './ldavis_prepared_initial_'+ str(number_topics) +'.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.display(LDAvis_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
